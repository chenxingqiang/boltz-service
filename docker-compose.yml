version: '3.8'

services:
  # Redis cache for MSA results
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Inference service for protein structure prediction
  inference:
    build:
      context: .
      dockerfile: docker/inference.Dockerfile
    ports:
      - "50051:50051"
    environment:
      - PYTHONPATH=/app
      - BOLTZ_CACHE_DIR=/data/cache
      - BOLTZ_MODEL_DIR=/data/models
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - model-data:/data/models
      - cache-data:/data/cache
      - ./output:/app/output
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; channel = grpc.insecure_channel('localhost:50051'); grpc.channel_ready_future(channel).result(timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MSA service for sequence alignment
  msa:
    build:
      context: .
      dockerfile: docker/msa/Dockerfile
    ports:
      - "50053:50053"
    environment:
      - PYTHONPATH=/app
      - BOLTZ_CACHE_DIR=/data/cache
      - BOLTZ_BFD_PATH=/data/bfd
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - bfd-data:/data/bfd
      - cache-data:/data/cache
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; channel = grpc.insecure_channel('localhost:50053'); grpc.channel_ready_future(channel).result(timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Training service for model training
  training:
    build:
      context: .
      dockerfile: docker/training.Dockerfile
    ports:
      - "50052:50052"
    environment:
      - PYTHONPATH=/app
      - DATA_PATH=/app/data
      - CHECKPOINT_PATH=/app/checkpoints
      - MODEL_PATH=/app/models
      - WANDB_SILENT=true
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - training-data:/app/data
      - checkpoint-data:/app/checkpoints
      - model-data:/app/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; channel = grpc.insecure_channel('localhost:50052'); grpc.channel_ready_future(channel).result(timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:v2.45.0
    ports:
      - "9090:9090"
    volumes:
      - ./k8s/monitoring/prometheus-configmap.yaml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    profiles:
      - monitoring

  # Grafana for visualization
  grafana:
    image: grafana/grafana:10.0.0
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    profiles:
      - monitoring

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:1.47
    ports:
      - "6831:6831/udp"   # Jaeger thrift compact
      - "16686:16686"     # Jaeger UI
      - "14268:14268"     # Jaeger collector HTTP
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    profiles:
      - monitoring

volumes:
  redis-data:
  model-data:
  cache-data:
  bfd-data:
  training-data:
  checkpoint-data:
  prometheus-data:
  grafana-data:

networks:
  default:
    name: boltz-network
